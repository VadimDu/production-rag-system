# Production RAG System Environment Configuration
# This file shows the recommended settings for the .env file
# Copy this file to .env and modify as needed

# =============================================================================
# DATABASE SETTINGS
# =============================================================================
# ChromaDB persist directory (absolute path recommended)
# If not set, defaults to: ./chroma_db
RAG_PERSIST_DIR=./chroma_db

# =============================================================================
# LOGGING SETTINGS
# =============================================================================
# Log file path (absolute path recommended)
# If not set, defaults to: ./rag_system.log
RAG_LOG_FILE=./rag_system.log

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
RAG_LOG_LEVEL=INFO

# =============================================================================
# EMBEDDING MODEL SETTINGS
# =============================================================================
# HuggingFace embedding model name
# Change to your preferred embedding model
RAG_EMBEDDING_MODEL=mixedbread-ai/mxbai-embed-large-v1

# =============================================================================
# LLM SETTINGS
# =============================================================================
# LLM provider: lmstudio, openai, anthropic, etc.
RAG_LLM_PROVIDER=lmstudio

# LLM model name (depends on provider)
RAG_LLM_MODEL=qwen/qwen3-next-80b

# LLM API key (not needed for LM Studio)
RAG_LLM_API_KEY=not-needed

# LLM base URL (for LM Studio or custom endpoints)
RAG_LLM_BASE_URL=http://localhost:1234/v1

# LLM temperature (0.0 to 2.0, lower = more deterministic, higher = more creative)
RAG_LLM_TEMPERATURE=1.0

# LLM maximum tokens (1 to 100000, controls response length)
RAG_LLM_MAX_TOKENS=32000

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
# Embedding batch size
RAG_EMBEDDING_BATCH_SIZE=32

# Maximum concurrent requests
RAG_MAX_CONCURRENT_REQUESTS=10

# Request timeout in seconds
# Increase for long queries
RAG_REQUEST_TIMEOUT=30

# =============================================================================
# SECURITY SETTINGS
# =============================================================================
# Maximum query length
RAG_MAX_QUERY_LENGTH=2000

# Maximum document size in bytes
RAG_MAX_DOCUMENT_SIZE=10000000

# =============================================================================
# MONITORING SETTINGS
# =============================================================================
# Enable metrics collection
RAG_ENABLE_METRICS=true

# Metrics server port
RAG_METRICS_PORT=8000

# =============================================================================
# RETRIEVAL SETTINGS
# =============================================================================
# Default retriever type: bm25, vec_semantic, ensemble
RAG_DEFAULT_RETRIEVER=vec_semantic

# Default number of document-chunks to retrieve
RAG_DEFAULT_K=5

# =============================================================================
# MEMORY SETTINGS
# =============================================================================
# Default memory type: buffer, summary
RAG_DEFAULT_MEMORY=buffer

# =============================================================================
# Example Usage
# =============================================================================
# To use this template:
# 1. Copy this file to .env:
#    cp .env.template .env
# 2. Edit .env with your actual values
# 3. Run the examples:
#    python examples/basic_usage.py